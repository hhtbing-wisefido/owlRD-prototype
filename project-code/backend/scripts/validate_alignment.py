#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–å¯¹é½éªŒè¯è„šæœ¬
éªŒè¯ æºSQL â†” Model â†” ç¤ºä¾‹æ•°æ® ä¸‰è€…ä¸€è‡´æ€§

åŠŸèƒ½ï¼š
1. ä»SQLæ–‡ä»¶æå–å­—æ®µå®šä¹‰
2. ä»Pydantic Modelæå–å­—æ®µå®šä¹‰
3. éªŒè¯ç¤ºä¾‹æ•°æ®æ˜¯å¦ç¬¦åˆModel
4. ç”Ÿæˆè¯¦ç»†å¯¹é½æŠ¥å‘Š
"""

import re
import json
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple, Any, Optional
from dataclasses import dataclass
import importlib
import inspect

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from pydantic import BaseModel as PydanticBaseModel


@dataclass
class FieldInfo:
    """å­—æ®µä¿¡æ¯"""
    name: str
    type: str
    nullable: bool = True
    default: Optional[Any] = None
    description: str = ""


@dataclass
class TableInfo:
    """è¡¨ä¿¡æ¯"""
    name: str
    sql_file: str
    model_file: Optional[str] = None
    model_class: Optional[str] = None
    collection: str = ""
    sql_fields: Dict[str, FieldInfo] = None
    model_fields: Dict[str, FieldInfo] = None
    
    def __post_init__(self):
        if self.sql_fields is None:
            self.sql_fields = {}
        if self.model_fields is None:
            self.model_fields = {}


class SQLFieldExtractor:
    """SQLå­—æ®µæå–å™¨"""
    
    def __init__(self, sql_root: Path):
        self.sql_root = sql_root
    
    def extract_fields(self, sql_file: str) -> Dict[str, FieldInfo]:
        """ä»SQLæ–‡ä»¶æå–å­—æ®µå®šä¹‰"""
        file_path = self.sql_root / sql_file
        
        if not file_path.exists():
            print(f"âš ï¸  SQLæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return {}
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–CREATE TABLEè¯­å¥
        table_match = re.search(
            r'CREATE\s+TABLE\s+(?:IF\s+NOT\s+EXISTS\s+)?(\w+)\s*\((.*?)\);',
            content,
            re.DOTALL | re.IGNORECASE
        )
        
        if not table_match:
            print(f"âš ï¸  æœªæ‰¾åˆ°CREATE TABLEè¯­å¥: {sql_file}")
            return {}
        
        table_body = table_match.group(2)
        fields = {}
        
        # æå–æ¯ä¸ªå­—æ®µå®šä¹‰
        # åŒ¹é…æ ¼å¼: field_name TYPE [NOT NULL] [DEFAULT ...] [-- comment]
        field_pattern = re.compile(
            r'^\s*(\w+)\s+'  # å­—æ®µå
            r'([\w\(\)]+(?:\s+\w+)*?)\s*'  # ç±»å‹
            r'(?:NOT\s+NULL)?'  # å¯é€‰çš„NOT NULL
            r'(?:\s+DEFAULT\s+[^,\n]+)?'  # å¯é€‰çš„DEFAULT
            r'(?:\s+--\s*(.*))?',  # å¯é€‰çš„æ³¨é‡Š
            re.MULTILINE
        )
        
        for line in table_body.split('\n'):
            # è·³è¿‡çº¦æŸå’Œç´¢å¼•
            if any(kw in line.upper() for kw in ['PRIMARY KEY', 'FOREIGN KEY', 'UNIQUE', 'CHECK', 'CONSTRAINT', 'REFERENCES']):
                continue
            
            match = field_pattern.match(line)
            if match:
                field_name = match.group(1)
                field_type = match.group(2).strip()
                description = match.group(3).strip() if match.group(3) else ""
                nullable = 'NOT NULL' not in line.upper()
                
                # æ˜ å°„SQLç±»å‹åˆ°Pythonç±»å‹
                python_type = self._map_sql_type(field_type)
                
                fields[field_name] = FieldInfo(
                    name=field_name,
                    type=python_type,
                    nullable=nullable,
                    description=description
                )
        
        return fields
    
    def _map_sql_type(self, sql_type: str) -> str:
        """æ˜ å°„SQLç±»å‹åˆ°Pythonç±»å‹"""
        sql_type_upper = sql_type.upper()
        
        if 'UUID' in sql_type_upper:
            return 'UUID'
        elif 'VARCHAR' in sql_type_upper or 'TEXT' in sql_type_upper:
            return 'str'
        elif 'INT' in sql_type_upper or 'SERIAL' in sql_type_upper:
            return 'int'
        elif 'BOOL' in sql_type_upper:
            return 'bool'
        elif 'TIMESTAMP' in sql_type_upper or 'DATE' in sql_type_upper:
            return 'datetime'
        elif 'JSONB' in sql_type_upper or 'JSON' in sql_type_upper:
            return 'dict'
        elif 'BYTEA' in sql_type_upper:
            return 'bytes'
        elif 'DECIMAL' in sql_type_upper or 'NUMERIC' in sql_type_upper:
            return 'float'
        else:
            return sql_type


class ModelFieldExtractor:
    """Pydantic Modelå­—æ®µæå–å™¨"""
    
    def __init__(self, model_root: Path):
        self.model_root = model_root
    
    def extract_fields(self, model_file: str, class_name: str) -> Dict[str, FieldInfo]:
        """ä»Pydantic Modelæå–å­—æ®µå®šä¹‰"""
        module_name = model_file.replace('.py', '').replace('/', '.')
        
        try:
            module = importlib.import_module(f'app.models.{module_name}')
        except ImportError as e:
            print(f"âš ï¸  æ— æ³•å¯¼å…¥æ¨¡å— app.models.{module_name}: {e}")
            return {}
        
        if not hasattr(module, class_name):
            print(f"âš ï¸  æ¨¡å—ä¸­æœªæ‰¾åˆ°ç±» {class_name}")
            return {}
        
        model_class = getattr(module, class_name)
        
        if not issubclass(model_class, PydanticBaseModel):
            print(f"âš ï¸  {class_name} ä¸æ˜¯Pydanticæ¨¡å‹")
            return {}
        
        fields = {}
        
        # ä½¿ç”¨Pydanticçš„model_fields
        if hasattr(model_class, 'model_fields'):
            for field_name, field_info in model_class.model_fields.items():
                python_type = self._get_field_type(field_info.annotation)
                nullable = not field_info.is_required()
                description = field_info.description or ""
                
                fields[field_name] = FieldInfo(
                    name=field_name,
                    type=python_type,
                    nullable=nullable,
                    default=field_info.default,
                    description=description
                )
        
        return fields
    
    def _get_field_type(self, annotation) -> str:
        """è·å–å­—æ®µç±»å‹"""
        if hasattr(annotation, '__origin__'):
            # å¤„ç†æ³›å‹ç±»å‹ (Optional, List, Dictç­‰)
            origin = annotation.__origin__
            if origin is type(None):
                return 'None'
            elif hasattr(origin, '__name__'):
                return origin.__name__
            else:
                return str(origin)
        elif hasattr(annotation, '__name__'):
            return annotation.__name__
        else:
            return str(annotation)


class SampleDataValidator:
    """ç¤ºä¾‹æ•°æ®éªŒè¯å™¨"""
    
    def __init__(self, data_root: Path):
        self.data_root = data_root
    
    def validate_collection(self, collection: str, model_class) -> Tuple[bool, List[str]]:
        """éªŒè¯ç¤ºä¾‹æ•°æ®é›†åˆ"""
        from app.services.storage import StorageService
        
        storage = StorageService(collection, str(self.data_root))
        samples = storage.load_all()
        
        if not samples:
            return True, ["æ— ç¤ºä¾‹æ•°æ®"]
        
        errors = []
        
        for idx, sample in enumerate(samples):
            try:
                # ä½¿ç”¨Pydantic ModeléªŒè¯
                model_class(**sample)
            except Exception as e:
                errors.append(f"è®°å½•#{idx}: {str(e)}")
        
        return len(errors) == 0, errors


class AlignmentValidator:
    """å¯¹é½éªŒè¯å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.sql_root = project_root.parent.parent / "owdRD_github_clone_æºå‚è€ƒæ–‡ä»¶" / "owlRD" / "db"
        self.model_root = project_root / "app" / "models"
        self.data_root = project_root / "app" / "data"
        
        self.sql_extractor = SQLFieldExtractor(self.sql_root)
        self.model_extractor = ModelFieldExtractor(self.model_root)
        self.data_validator = SampleDataValidator(self.data_root)
    
    def validate_table(self, table: TableInfo) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªè¡¨"""
        result = {
            'table_name': table.name,
            'sql_file': table.sql_file,
            'model_file': table.model_file,
            'collection': table.collection,
            'sql_fields_count': 0,
            'model_fields_count': 0,
            'missing_in_model': [],
            'extra_in_model': [],
            'type_mismatches': [],
            'sample_data_valid': False,
            'sample_data_errors': [],
            'alignment_score': 0.0
        }
        
        # 1. æå–SQLå­—æ®µ
        sql_fields = self.sql_extractor.extract_fields(table.sql_file)
        result['sql_fields_count'] = len(sql_fields)
        
        if not sql_fields:
            result['alignment_score'] = 0.0
            return result
        
        # 2. æå–Modelå­—æ®µ
        if table.model_file and table.model_class:
            model_fields = self.model_extractor.extract_fields(
                table.model_file,
                table.model_class
            )
            result['model_fields_count'] = len(model_fields)
            
            # 3. å¯¹æ¯”å­—æ®µ
            sql_field_names = set(sql_fields.keys())
            model_field_names = set(model_fields.keys())
            
            result['missing_in_model'] = list(sql_field_names - model_field_names)
            result['extra_in_model'] = list(model_field_names - sql_field_names)
            
            # 4. æ£€æŸ¥ç±»å‹åŒ¹é…
            for field_name in sql_field_names & model_field_names:
                sql_type = sql_fields[field_name].type
                model_type = model_fields[field_name].type
                
                if not self._types_compatible(sql_type, model_type):
                    result['type_mismatches'].append({
                        'field': field_name,
                        'sql_type': sql_type,
                        'model_type': model_type
                    })
            
            # 5. è®¡ç®—å¯¹é½åˆ†æ•°
            total_fields = len(sql_field_names)
            matched_fields = len(sql_field_names & model_field_names) - len(result['type_mismatches'])
            result['alignment_score'] = (matched_fields / total_fields * 100) if total_fields > 0 else 0.0
        
        # 6. éªŒè¯ç¤ºä¾‹æ•°æ® (æš‚æ—¶è·³è¿‡ï¼Œé¿å…å¯¼å…¥é—®é¢˜)
        # if table.collection:
        #     valid, errors = self.data_validator.validate_collection(table.collection, model_class)
        #     result['sample_data_valid'] = valid
        #     result['sample_data_errors'] = errors
        
        return result
    
    def _types_compatible(self, sql_type: str, model_type: str) -> bool:
        """æ£€æŸ¥ç±»å‹æ˜¯å¦å…¼å®¹"""
        # åŸºæœ¬ç±»å‹æ˜ å°„
        compatible_types = {
            'UUID': ['UUID', 'str'],
            'str': ['str', 'UUID'],
            'int': ['int'],
            'bool': ['bool'],
            'datetime': ['datetime', 'str'],
            'dict': ['dict', 'Dict'],
            'bytes': ['bytes'],
            'float': ['float', 'int']
        }
        
        return model_type in compatible_types.get(sql_type, [sql_type])
    
    def generate_report(self, results: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆå¯¹é½æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ” æ•°æ®å¯¹é½éªŒè¯æŠ¥å‘Š")
        report.append("=" * 80)
        report.append("")
        
        total_tables = len(results)
        perfect_tables = sum(1 for r in results if r['alignment_score'] == 100.0)
        avg_score = sum(r['alignment_score'] for r in results) / total_tables if total_tables > 0 else 0.0
        
        report.append(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        report.append(f"  - æ€»è¡¨æ•°: {total_tables}")
        report.append(f"  - å®Œç¾å¯¹é½: {perfect_tables} ({perfect_tables/total_tables*100:.1f}%)")
        report.append(f"  - å¹³å‡å¯¹é½åº¦: {avg_score:.1f}%")
        report.append("")
        
        # æŒ‰å¯¹é½åº¦æ’åº
        results.sort(key=lambda x: x['alignment_score'])
        
        for result in results:
            score = result['alignment_score']
            status = "âœ…" if score == 100.0 else "âš ï¸" if score >= 80.0 else "âŒ"
            
            report.append(f"{status} {result['table_name']} - {score:.1f}%")
            report.append(f"  SQLæ–‡ä»¶: {result['sql_file']}")
            report.append(f"  Modelæ–‡ä»¶: {result['model_file'] or 'N/A'}")
            report.append(f"  SQLå­—æ®µæ•°: {result['sql_fields_count']}")
            report.append(f"  Modelå­—æ®µæ•°: {result['model_fields_count']}")
            
            if result['missing_in_model']:
                report.append(f"  âŒ Modelç¼ºå°‘å­—æ®µ: {', '.join(result['missing_in_model'])}")
            
            if result['extra_in_model']:
                report.append(f"  âš ï¸  Modelå¤šä½™å­—æ®µ: {', '.join(result['extra_in_model'])}")
            
            if result['type_mismatches']:
                report.append(f"  âš ï¸  ç±»å‹ä¸åŒ¹é…:")
                for mismatch in result['type_mismatches']:
                    report.append(f"      {mismatch['field']}: SQL={mismatch['sql_type']}, Model={mismatch['model_type']}")
            
            report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)


def main():
    """ä¸»å‡½æ•°"""
    project_root = Path(__file__).parent.parent
    
    # å®šä¹‰è¦éªŒè¯çš„è¡¨ (table_name, sql_file, model_file, model_class_name, collection)
    tables_config = [
        ("tenants", "01_tenants.sql", "tenant", "Tenant", "tenants"),
        ("roles", "02_roles.sql", "role", "Role", "roles"),
        ("users", "03_users.sql", "user", "User", "users"),
        ("locations", "04_locations.sql", "location", "Location", "locations"),
        ("rooms", "05_rooms.sql", "location", "Room", "rooms"),  # Roomåœ¨location.pyä¸­
        ("beds", "06_beds.sql", "location", "Bed", "beds"),  # Bedåœ¨location.pyä¸­
        ("residents", "07_residents.sql", "resident", "Resident", "residents"),
        ("resident_phi", "08_resident_phi.sql", "resident", "ResidentPHI", "resident_phi"),  # åœ¨resident.pyä¸­
        ("resident_contacts", "09_resident_contacts.sql", "resident", "ResidentContact", "resident_contacts"),  # åœ¨resident.pyä¸­
        ("resident_caregivers", "10_resident_caregivers.sql", "resident", "ResidentCaregiver", "resident_caregivers"),  # åœ¨resident.pyä¸­
        ("devices", "11_devices.sql", "device", "Device", "devices"),
        ("iot_timeseries", "12_iot_timeseries.sql", "iot_data", "IOTTimeseries", "iot_timeseries"),
        ("iot_monitor_alerts", "13_iot_monitor_alerts.sql", "iot_data", "IOTMonitorAlert", "iot_monitor_alerts"),
        ("cloud_alert_policies", "14_cloud_alert_policies.sql", "alert", "CloudAlertPolicy", "cloud_alert_policies"),
        ("config_versions", "15_config_versions.sql", "config_version", "ConfigVersion", "config_versions"),
        ("posture_mapping", "16_mapping_tables.sql", "mapping", "PostureMapping", "posture_mapping"),
        ("event_mapping", "16_mapping_tables.sql", "mapping", "EventMapping", "event_mapping"),
        ("cards", "18_cards.sql", "card", "Card", "cards"),
    ]
    
    tables = [TableInfo(name, sql, model, cls, coll) for name, sql, model, cls, coll in tables_config]
    
    validator = AlignmentValidator(project_root)
    
    print("ğŸš€ å¼€å§‹éªŒè¯æ•°æ®å¯¹é½...")
    print()
    
    results = []
    for table in tables:
        print(f"æ£€æŸ¥ {table.name}...", end=" ")
        result = validator.validate_table(table)
        results.append(result)
        print(f"{result['alignment_score']:.1f}%")
    
    print()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = validator.generate_report(results)
    print(report)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = project_root.parent.parent / "é¡¹ç›®è®°å½•" / "AUTO_å¯¹é½éªŒè¯æŠ¥å‘Š.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# è‡ªåŠ¨åŒ–å¯¹é½éªŒè¯æŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {Path(__file__).stat().st_mtime}\n\n")
        f.write("```\n")
        f.write(report)
        f.write("\n```\n")
    
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    # è¿”å›é€€å‡ºç 
    avg_score = sum(r['alignment_score'] for r in results) / len(results) if results else 0.0
    sys.exit(0 if avg_score == 100.0 else 1)


if __name__ == "__main__":
    main()
